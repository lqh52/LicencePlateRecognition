{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_plate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbGBY49dJn57",
        "outputId": "479c0376-f2d8-4f6d-9983-6c01e6e8dbc6"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "IMAGE_SIZE = 416\n",
        "S = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\n",
        "ANCHORS = [\n",
        "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
        "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
        "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
        "]\n",
        "\n",
        "scaled_anchors = (torch.tensor(ANCHORS) * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2))\n",
        "\n",
        "TRANSFORMS = transforms.Compose([\n",
        "    transforms.Resize(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0,0,0], std=[1,1,1])\n",
        "])\n",
        "\n",
        "CLASS_LABELS = ['Plate']\n",
        "\n",
        "config = [\n",
        "    # Darknet-53\n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],\n",
        "\n",
        "    # YOLO\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]\n",
        "\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.leaky = nn.LeakyReLU(0.1)\n",
        "        self.use_bn_act = bn_act\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_bn_act:\n",
        "            return self.leaky(self.bn(self.conv(x)))\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for repeat in range(num_repeats):\n",
        "            self.layers += [\n",
        "                nn.Sequential(\n",
        "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
        "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        self.use_residual = use_residual\n",
        "        self.num_repeats = num_repeats\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            if self.use_residual:\n",
        "                x = x + layer(x)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ScalePrediction(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.pred = nn.Sequential(\n",
        "            CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n",
        "            CNNBlock(\n",
        "                2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1\n",
        "            ),\n",
        "        )\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (\n",
        "            self.pred(x)\n",
        "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
        "            .permute(0, 1, 3, 4, 2)\n",
        "        )\n",
        "\n",
        "\n",
        "class YOLOv3(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=20):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.in_channels = in_channels\n",
        "        self.layers = self._create_conv_layers()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []  # for each scale\n",
        "        route_connections = []\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, ScalePrediction):\n",
        "                outputs.append(layer(x))\n",
        "                continue\n",
        "\n",
        "            x = layer(x)\n",
        "\n",
        "            if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n",
        "                route_connections.append(x)\n",
        "\n",
        "            elif isinstance(layer, nn.Upsample):\n",
        "                x = torch.cat([x, route_connections[-1]], dim=1)\n",
        "                route_connections.pop()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _create_conv_layers(self):\n",
        "        layers = nn.ModuleList()\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for module in config:\n",
        "            if isinstance(module, tuple):\n",
        "                out_channels, kernel_size, stride = module\n",
        "                layers.append(\n",
        "                    CNNBlock(\n",
        "                        in_channels,\n",
        "                        out_channels,\n",
        "                        kernel_size=kernel_size,\n",
        "                        stride=stride,\n",
        "                        padding=1 if kernel_size == 3 else 0,\n",
        "                    )\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "\n",
        "            elif isinstance(module, list):\n",
        "                num_repeats = module[1]\n",
        "                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))\n",
        "\n",
        "            elif isinstance(module, str):\n",
        "                if module == \"S\":\n",
        "                    layers += [\n",
        "                        ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n",
        "                        CNNBlock(in_channels, in_channels // 2, kernel_size=1),\n",
        "                        ScalePrediction(in_channels // 2, num_classes=self.num_classes),\n",
        "                    ]\n",
        "                    in_channels = in_channels // 2\n",
        "\n",
        "                elif module == \"U\":\n",
        "                    layers.append(nn.Upsample(scale_factor=2),)\n",
        "                    in_channels = in_channels * 3\n",
        "\n",
        "        return layers\n",
        "\n",
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "    if box_format == \"midpoint\":\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "    if box_format == \"corners\":\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
        "\n",
        "def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
        "    assert type(bboxes) == list\n",
        "\n",
        "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
        "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
        "    bboxes_after_nms = []\n",
        "\n",
        "    while bboxes:\n",
        "        chosen_box = bboxes.pop(0)\n",
        "\n",
        "        bboxes = [\n",
        "            box\n",
        "            for box in bboxes\n",
        "            if box[0] != chosen_box[0]\n",
        "            or intersection_over_union(\n",
        "                torch.tensor(chosen_box[2:]),\n",
        "                torch.tensor(box[2:]),\n",
        "                box_format=box_format,\n",
        "            )\n",
        "            < iou_threshold\n",
        "        ]\n",
        "\n",
        "        bboxes_after_nms.append(chosen_box)\n",
        "\n",
        "    return bboxes_after_nms\n",
        "\n",
        "def cells_to_bboxes(predictions, anchors, S, is_preds=True):\n",
        "    BATCH_SIZE = predictions.shape[0]\n",
        "    num_anchors = len(anchors)\n",
        "    box_predictions = predictions[..., 1:5]\n",
        "    if is_preds:\n",
        "        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n",
        "        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n",
        "        box_predictions[..., 2:] = torch.exp(box_predictions[..., 2:]) * anchors\n",
        "        scores = torch.sigmoid(predictions[..., 0:1])\n",
        "        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n",
        "    else:\n",
        "        scores = predictions[..., 0:1]\n",
        "        best_class = predictions[..., 5:6]\n",
        "\n",
        "    cell_indices = (\n",
        "        torch.arange(S)\n",
        "        .repeat(predictions.shape[0], 3, S, 1)\n",
        "        .unsqueeze(-1)\n",
        "        .to(predictions.device)\n",
        "    )\n",
        "    x = 1 / S * (box_predictions[..., 0:1] + cell_indices)\n",
        "    y = 1 / S * (box_predictions[..., 1:2] + cell_indices.permute(0, 1, 3, 2, 4))\n",
        "    w_h = 1 / S * box_predictions[..., 2:4]\n",
        "    converted_bboxes = torch.cat((best_class, scores, x, y, w_h), dim=-1).reshape(BATCH_SIZE, num_anchors * S * S, 6)\n",
        "    return converted_bboxes.tolist()\n",
        "\n",
        "def predict(model, img_path, scaled_anchors=scaled_anchors, conf_threshold = 0.7, iou_threshold = 0.5):\n",
        "    image = Image.open(img_path)\n",
        "    image = TRANSFORMS(image)\n",
        "    image = torch.autograd.Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    pred = model(image)\n",
        "    bboxes = []\n",
        "    for i in range(3):\n",
        "        _, A, S, _, _ = pred[i].shape\n",
        "        anchor = scaled_anchors[i]\n",
        "        boxes_scale_i = cells_to_bboxes(\n",
        "            pred[i], anchor, S=S, is_preds=True\n",
        "        )\n",
        "        for idx, (box) in enumerate(boxes_scale_i):\n",
        "            bboxes += box\n",
        "\n",
        "    nms_boxes = non_max_suppression(\n",
        "        bboxes, iou_threshold=iou_threshold, threshold=conf_threshold, box_format=\"midpoint\",\n",
        "    )\n",
        "    nms_boxes = [box for box in nms_boxes if box[0]==0]\n",
        "    return nms_boxes, image[0].permute(1,2,0).detach().cpu()\n",
        "\n",
        "def plot_image(image, boxes):\n",
        "    cmap = plt.get_cmap(\"tab20b\")\n",
        "    class_labels = CLASS_LABELS*20\n",
        "    colors = [cmap(i) for i in np.linspace(0, 1, len(class_labels))]\n",
        "    im = np.array(image)\n",
        "    height, width, _ = im.shape\n",
        "\n",
        "    fig, ax = plt.subplots(1)\n",
        "    # Display the image\n",
        "    ax.imshow(im)\n",
        "\n",
        "    for box in boxes:\n",
        "        assert len(box) == 6, \"box should contain class pred, confidence, x, y, width, height\"\n",
        "        class_pred = box[0]\n",
        "        box = box[2:]\n",
        "        upper_left_x = box[0] - box[2] / 2\n",
        "        upper_left_y = box[1] - box[3] / 2\n",
        "        rect = patches.Rectangle(\n",
        "            (upper_left_x * width, upper_left_y * height),\n",
        "            box[2] * width,\n",
        "            box[3] * height,\n",
        "            linewidth=2,\n",
        "            edgecolor=colors[int(class_pred)],\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        plt.text(\n",
        "            upper_left_x * width,\n",
        "            upper_left_y * height,\n",
        "            s=class_labels[int(class_pred)],\n",
        "            color=\"white\",\n",
        "            verticalalignment=\"top\",\n",
        "            bbox={\"color\": colors[int(class_pred)], \"pad\": 0},\n",
        "        )\n",
        "    plt.show()\n",
        "\n",
        "def plot_crop(image, boxes):\n",
        "    im = np.array(image)\n",
        "    height, width, _ = im.shape\n",
        "    for i, box in enumerate(boxes):\n",
        "      box = box[2:]\n",
        "      upper_left_x = box[0] - box[2] / 2\n",
        "      upper_left_x = int(width* upper_left_x)\n",
        "      upper_left_y = box[1] - box[3] / 2\n",
        "      upper_left_y = int(height * upper_left_y)\n",
        "      lower_right_x = box[0] + box[2] / 2\n",
        "      lower_right_x = int(width* lower_right_x)\n",
        "      lower_right_y = box[1] + box[3] / 2\n",
        "      lower_right_y = int(height * lower_right_y)\n",
        "      crop = im[upper_left_y: lower_right_y+1, upper_left_x: lower_right_x+1, :]\n",
        "      plt.subplot(1, len(boxes), i+1)\n",
        "      plt.imshow(crop)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}